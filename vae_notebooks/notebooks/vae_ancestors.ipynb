{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ded3c9d458a5f2c",
   "metadata": {},
   "source": [
    "### Project Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3db5c55f2bd64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dahala/GitHub/VAE-enzymes/vae_notebooks\n",
      "/Users/dahala/GitHub/VAE-enzymes/vae_notebooks/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import subprocess\n",
    "from matplotlib import pyplot as plt\n",
    "from Bio import SeqIO\n",
    "from importlib import reload\n",
    "\n",
    "import minimal_version.parser_handler\n",
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks/\n",
    "from minimal_version.preprocess_msa import Preprocessor, weight_sequences\n",
    "from minimal_version.msa import MSA\n",
    "from minimal_version.utils import Capturing, store_to_pkl, store_to_fasta, load_from_pkl\n",
    "\n",
    "from minimal_version.train import setup_train, Train\n",
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks/notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3ea326c408c04",
   "metadata": {},
   "source": [
    "### Project Configuration\n",
    "Configure your project using the configuration file. Use the modelConfig template as a guide. \n",
    "\n",
    "A value of -1 indicates that the default value will be used. \n",
    "\n",
    "Please note that every time the RunSetup class is executed, the current version of the configuration file will be copied to your specified directory, allowing you to review all set parameters at any time.  \n",
    "\n",
    "Run just one of the two cell below (working with/without Pfam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efbcc7f5166be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIGURATION_FILE = \"pfamGT1Small_filtered_hmm.json\"\n",
    "#CONFIGURATION_FILE = \"msaEnzymeMiner_PtUGT1.json\"\n",
    "CONFIGURATION_FILE = \"msaGASP_bigMSA.json\"\n",
    "run = minimal_version.parser_handler.RunSetup(CONFIGURATION_FILE)\n",
    "print(f\" Working with {CONFIGURATION_FILE} configuration file!\")\n",
    "PFAM_INPUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cids = [7257, 79964, 445154, 5315892, 5280343, 444539, 6549, 445858, 1548943, 932]\n",
    "sub_idx = 0\n",
    "#CONFIGURATION_FILE = f\"json_files_GASPcondition/msaGASP_bigMSA_{sub_cids[sub_idx]}.json\"\n",
    "CONFIGURATION_FILE = f\"json_files_GASPcondition/msaEnzymeMiner_PtUGT1_{sub_cids[sub_idx]}.json\"\n",
    "#CONFIGURATION_FILE = f\"json_files_GASPcondition/msaEnzymeMiner_PtUGT1_3dim_{sub_cids[sub_idx]}.json\"\n",
    "run = minimal_version.parser_handler.RunSetup(CONFIGURATION_FILE)\n",
    "print(f\" Working with {CONFIGURATION_FILE} configuration file!\")\n",
    "PFAM_INPUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da51ab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file stored in ../results/EnzymeMiner_PtUGT1_DCA_DCP_345/config/2024-09-30_10-42.json\n",
      " Working with json_files_GASPcondition/msaEnzymeMiner_PtUGT1_DCA_DCP_345.json configuration file!\n"
     ]
    }
   ],
   "source": [
    "CONFIGURATION_FILE = f\"json_files_GASPcondition/msaEnzymeMiner_PtUGT1_DCA_DCP_345.json\"\n",
    "#CONFIGURATION_FILE = f\"json_files_GASPcondition/msaEnzymeMiner_PtUGT1_DCA_DCP_200.json\"\n",
    "run = minimal_version.parser_handler.RunSetup(CONFIGURATION_FILE)\n",
    "print(f\" Working with {CONFIGURATION_FILE} configuration file!\")\n",
    "PFAM_INPUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730296bc5073d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION_FILE = \"pfamGT1Small.json\"\n",
    "run = minimal_version.parser_handler.RunSetup(CONFIGURATION_FILE)\n",
    "print(f\" Working with {CONFIGURATION_FILE} configuration file!\")\n",
    "PFAM_INPUT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731d35f",
   "metadata": {},
   "source": [
    "### HMM alignment preprocessing\n",
    "This preprocessing step generates a Hidden Markov Model (HMM) profile from a Multiple Sequence Alignment (MSA) and realigns the sequences from the MSA to this profile, resulting in a HMM-MSA. \n",
    "\n",
    "The HMM-MSA can then be utilized as a classical input MSA in the Variational Autoencoder (VAE) pipeline, offering the advantage of facilitating the alignment of different query sequences to the HMM profile. If this option is enabled, ensure that the dataset path in the configuration file is updated to the new fixed path to maintain consistency in future experiments.\n",
    "\n",
    "Install hmmer to your system first: for example **apt install hmmer** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use hmm aligner run this cell\n",
    "hmmAligner = HMMAligner(run)\n",
    "hmmAligner.buildHMM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmAligner.hmmer_align(\"yourCustomFasta\")  # you can align your custom sequences to the hmm model here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635675ba628f4ed",
   "metadata": {},
   "source": [
    "### MSA preprocessing\n",
    "Prepare your MSA for training by filtering it according to the queries specified in the configuration file. This includes both the query sequences and any fixed sequences defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7b64db1b86d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSA in ../datasets/EnzymeMiner_PtUGT1_fix.afa loaded\n",
      "number of sequences: 3437\n",
      "Trimmed MSA has 3416 sequences and the width is 444\n",
      "Trimmed MSA is stored at ../results/EnzymeMiner_PtUGT1_DCA_DCP_345/msa/trimmed_msa.fasta\n",
      "Training MSA has 3416 sequences and the width is 444\n",
      "Training MSA is stored at ../results/EnzymeMiner_PtUGT1_DCA_DCP_345/msa/training_msa.fasta\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocess MSA and prepare it for VAE model training\n",
    "\"\"\"\n",
    "\n",
    "# logging\n",
    "msa_log = open(os.path.join(run.logs, 'msa_log.txt'), \"w\")\n",
    "\n",
    "# MSA loading\n",
    "if PFAM_INPUT:\n",
    "    msa = MSA.load_pfam(run.dataset)\n",
    "else:\n",
    "    msa = MSA.load_msa(run.dataset)\n",
    "MSA.amino_acid_dict(run.pickles)\n",
    "msg = f\"MSA in {run.dataset} loaded\\n\" \\\n",
    "      f\"number of sequences: {len(list(msa.keys()))}\"\n",
    "print(msg)\n",
    "msa_log.write(msg + f'\\n{\"=\"*80}\\n')\n",
    "\n",
    "# MSA preprocessing\n",
    "preprocessor = Preprocessor(run)\n",
    "with Capturing() as output:\n",
    "    msa, msa_keys = preprocessor.trim_msa(msa)\n",
    "msa_log.write(\" MSA Preprocessing \\n\" + \"\\n\".join(output) + f'\\n{\"=\"*80}\\n')\n",
    "assert (msa.shape[0] == len(msa_keys))\n",
    "trim_file_path = os.path.join(run.msa, \"trimmed_msa.fasta\")\n",
    "msg = f\"Trimmed MSA has {msa.shape[0]} sequences and the width is {msa.shape[1]}\\n\" \\\n",
    "      f\"Trimmed MSA is stored at {trim_file_path}\"\n",
    "print(msg)\n",
    "msa_log.write(msg + f'\\n{\"=\"*80}\\n')\n",
    "msa_num_dict_shuffled = {k: seq for k, seq in zip(msa_keys, msa)}  # transform to dictionary, have keys together\n",
    "# but secure that query and fixed sequences are at the beginning \n",
    "msa_num_dict = {k: msa_num_dict_shuffled[k] for k in preprocessor.keep_keys}\n",
    "msa_num_dict.update({k: msa_num_dict_shuffled[k] for k in msa_num_dict_shuffled if k not in preprocessor.keep_keys})\n",
    "\n",
    "trimmed_msa = MSA.number_to_amino(msa_num_dict)\n",
    "store_to_fasta(trimmed_msa, trim_file_path)\n",
    "store_to_pkl({run.query: trimmed_msa[run.query]}, os.path.join(run.pickles, \"reference_seq.pkl\"))\n",
    "\n",
    "# Filtering or weighting\n",
    "with Capturing() as output:\n",
    "    if run.clustering:  # MSA filtering\n",
    "        print(f\"MSA {run.identity}% identity filtering step\")\n",
    "        msa_num_dict = preprocessor.identity_filtering(msa_num_dict)\n",
    "        msa, training_alg = preprocessor.get_keys_file_and_np_sequences(msa_num_dict)  # Overlap one treemmer\n",
    "        seq_weight = np.ones(msa.shape[0])  # we just provide uniform weights for all sequences\n",
    "    else:  # otherwise the weighting mechanism will be applied\n",
    "        msa, training_alg = preprocessor.get_keys_file_and_np_sequences(msa_num_dict)  # Overlap one treemmer\n",
    "        seq_weight = weight_sequences(msa)\n",
    "msa_log.write(\"\\n\".join(output))\n",
    "train_msa_file_path = os.path.join(run.msa, \"training_msa.fasta\")\n",
    "training_alg = MSA.number_to_amino(training_alg)\n",
    "store_to_fasta(training_alg, train_msa_file_path)\n",
    "msg = f\"Training MSA has {msa.shape[0]} sequences and the width is {msa.shape[1]}\\n\" \\\n",
    "      f\"Training MSA is stored at {train_msa_file_path}\"\n",
    "print(msg)\n",
    "msa_log.write(msg + f'\\n{\"=\" * 80}\\n')\n",
    "\n",
    "store_to_pkl(seq_weight, os.path.join(run.pickles, \"seq_weight.pkl\"))\n",
    "store_to_pkl(training_alg, os.path.join(run.pickles, \"training_alignment.pkl\"))\n",
    "\n",
    "# MSA one-hot encoding\n",
    "binary = MSA.number_to_binary(msa)\n",
    "store_to_pkl(binary, os.path.join(run.pickles, \"seq_msa_binary.pkl\"))\n",
    "msa_log.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e068316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(run.pickles+ \"/msa_columns.pkl\", \"rb\") as input_file:\n",
    "   msa_columns = pickle.load(input_file)\n",
    "   \n",
    "def fix_seqs(input_string):\n",
    "    seq_ = input_string.replace('.', '')\n",
    "    seq_ = ''.join([char for char in seq_ if not char.islower()])\n",
    "    return seq_\n",
    "\n",
    "def gaplimiter(seq,threshold=0.7):\n",
    "    gap_percent = seq.count('-') / len(seq)\n",
    "    if gap_percent > threshold:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def gaplimiter_df(df,threshold=0.7):\n",
    "    return df[df['trimmed_afa'].apply(lambda x: gaplimiter(x,threshold))]\n",
    "\n",
    "def apply_msa_mask(msa_df, msa_columns):\n",
    "    msa_df['trimmed_afa'] = msa_df['afa'].apply(lambda x: ''.join([x[i] for i in msa_columns]))\n",
    "    return msa_df\n",
    "\n",
    "def hmmer_align(fasta_name,hmm_model,out_path,hmmer_path='/Users/dahala/Projects/HMMER/bin',fasta_ext = 'faa'):\n",
    "    subprocess.run(f'{hmmer_path}/hmmalign --trim --outformat afa /Users/dahala/GitHub/VAE-enzymes/hmm_model/{hmm_model}.hmm ../datasets/{fasta_name}.{fasta_ext} > {out_path}/hmm/{fasta_name}.afa', shell=True, executable=\"/bin/zsh\")\n",
    "    return f'{out_path}/hmm/{fasta_name}.afa'\n",
    "\n",
    "def aligned_df(afa_path,msa_columns=msa_columns):\n",
    "    dict = {seq.description: fix_seqs(str(seq.seq)) for seq in SeqIO.parse(afa_path, \"fasta\")}\n",
    "    df = pd.DataFrame.from_dict(dict, orient='index', columns=['afa'])\n",
    "    df = apply_msa_mask(df, msa_columns)\n",
    "    return df\n",
    "\n",
    "def encode_custom_seqs(fasta_name,hmm_model,out_path,msa_columns=msa_columns,fasta_ext = 'faa',model= f'vae_fold_0.model',batch_size=1):\n",
    "    afa_path = hmmer_align(fasta_name,hmm_model,out_path,fasta_ext = fasta_ext)\n",
    "    df = aligned_df(afa_path,msa_columns)\n",
    "    run.weights = f'{out_path}/model/{model}'\n",
    "    latent_space = LatentSpace(run)\n",
    "    mu1_ = []\n",
    "    mu2_ = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        latent_embeddings = latent_space.encode(df['trimmed_afa'].to_list()[i:i+batch_size])[0]\n",
    "        mu1_.append(latent_embeddings[:,0])\n",
    "        mu2_.append(latent_embeddings[:,1])\n",
    "    df['mu1'] = np.concatenate(mu1_)\n",
    "    df['mu2'] = np.concatenate(mu2_)\n",
    "    return df\n",
    "\n",
    "def encode_custom_seqs_conditional(fasta_name,hmm_model,out_path,label_list,msa_columns=msa_columns,fasta_ext = 'faa',model= f'vae_fold_0.model'):\n",
    "    afa_path = hmmer_align(fasta_name,hmm_model,out_path,fasta_ext = fasta_ext)\n",
    "    df = aligned_df(afa_path,msa_columns)\n",
    "    run.weights = f'{out_path}/model/{model}'\n",
    "    latent_space = LatentSpace(run)\n",
    "    mu1_ = []\n",
    "    mu2_ = []\n",
    "    for i in range(0, len(df)):\n",
    "        encoding = df['trimmed_afa'].to_list()[i]\n",
    "        label = label_list[i]\n",
    "        latent_embeddings = latent_space.encode(encoding,c=label)[0]\n",
    "        mu1_.append(latent_embeddings[:,0])\n",
    "        mu2_.append(latent_embeddings[:,1])\n",
    "    df['mu1'] = np.concatenate(mu1_)\n",
    "    df['mu2'] = np.concatenate(mu2_)\n",
    "    return df\n",
    "\n",
    "def encode_custom_seqs_conditional_3D(fasta_name,hmm_model,out_path,label_list,msa_columns=msa_columns,fasta_ext = 'faa',model= f'vae_fold_0.model'):\n",
    "    afa_path = hmmer_align(fasta_name,hmm_model,out_path,fasta_ext = fasta_ext)\n",
    "    df = aligned_df(afa_path,msa_columns)\n",
    "    run.weights = f'{out_path}/model/{model}'\n",
    "    latent_space = LatentSpace(run)\n",
    "    mu1_ = []\n",
    "    mu2_ = []\n",
    "    mu3_ = []\n",
    "    for i in range(0, len(df)):\n",
    "        encoding = df['trimmed_afa'].to_list()[i]\n",
    "        label = label_list[i]\n",
    "        latent_embeddings = latent_space.encode(encoding,c=label)[0]\n",
    "        mu1_.append(latent_embeddings[:,0])\n",
    "        mu2_.append(latent_embeddings[:,1])\n",
    "        mu3_.append(latent_embeddings[:,2])\n",
    "    df['mu1'] = np.concatenate(mu1_)\n",
    "    df['mu2'] = np.concatenate(mu2_)\n",
    "    df['mu3'] = np.concatenate(mu3_)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b8052e59434e0",
   "metadata": {},
   "source": [
    "#### Conditional labels\n",
    "Before starting the training process, ensure that your labels are properly preprocessed if you intend to use them for **conditional training**. \n",
    "\n",
    "This involves converting your labels into a suitable format, such as one-hot or integer encoding (see and modify **custom_classifier** function). \n",
    "\n",
    "Additionally, specify the number of classes represented by your labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb230990f8c32233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of classes\n",
    "N_CLASSES = 2\n",
    "def parse_conditional_labels_to_categories(file_name):\n",
    "    \"\"\" Parse conditional label file \"\"\"\n",
    "    # Please specify your classification function to the bins, the interface of function must stay the same, example\n",
    "    def custom_classifier(prob_vals) -> torch.Tensor:\n",
    "        label = torch.zeros(N_CLASSES)\n",
    "        for i,val in enumerate(prob_vals):\n",
    "            if val > run.prob_threshold:\n",
    "                label[i] = 1\n",
    "        return label\n",
    "    \n",
    "    label_dict = {}\n",
    "    prob_df = pd.read_csv(file_name,delimiter='\\t',header=0)\n",
    "    for acc,label_vals in zip(prob_df.enzyme,prob_df.iloc[:,1:].values):\n",
    "            if label_vals is None:\n",
    "                print(f\"Error while parsing labels, accession {acc} does not have labels\")\n",
    "                exit(1)\n",
    "            label_dict[acc] = custom_classifier(label_vals)\n",
    "    return label_dict\n",
    "\n",
    "\"\"\" In the case of conditional model please preprocess labels \"\"\"\n",
    "label_file_path = run.conditional_labels  # you can specify it in the configuration path or provide custom one \n",
    "\n",
    "# Now get labels from your file, simple txt or similar file with sequence accession\\tlabel_value pair per line (modify function as needed)  \n",
    "label_dict = parse_conditional_labels_to_categories(label_file_path)\n",
    "\n",
    "labels_file_pkl = os.path.join(run.conditional_data, \"conditional_labels_to_categories.pkl\")\n",
    "msa_keys = load_from_pkl(os.path.join(run.pickles, \"keys_list.pkl\"))\n",
    "\n",
    "# get labels to the similar order as in msa (just in case, to enable using indexes in training method)\n",
    "msa_key_label_order = {}\n",
    "array_of_labels = torch.zeros(len(msa_keys), N_CLASSES)\n",
    "for label_i, msa_key in enumerate(msa_keys):\n",
    "    try:\n",
    "        msa_key_fix = msa_key.split()[0]\n",
    "        msa_key_label_order[msa_key] = label_dict[msa_key_fix]\n",
    "        array_of_labels[label_i] = label_dict[msa_key_fix]\n",
    "    except KeyError:\n",
    "        print(f\"{msa_key} is not in the label_dict, please provide labels for all sequences\")\n",
    "        exit(1)\n",
    "        \n",
    "# now store in both raw and text version\n",
    "store_to_pkl(array_of_labels, labels_file_pkl)\n",
    "with open(os.path.join(run.conditional_data, \"msa_key_label_order.txt\"), 'w') as txt_labels:\n",
    "    for k, label_tensor in msa_key_label_order.items():\n",
    "        txt_labels.write(f\"{k} {label_tensor}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531eb8f7d84c621",
   "metadata": {},
   "source": [
    "### Training of the model\n",
    "Select the models you would like to work with and prepare data for training and benchmarking if selected in configuration file. \n",
    "\n",
    "If you select a conditional model please see above cell and prepare labels for it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720546aea5acc95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Configure model \"\"\"\n",
    "available_models = [\"vae\", \"vae_conditional\"]\n",
    "model_selected = available_models[1]\n",
    "\n",
    "\"\"\" Prepare data for training \"\"\"\n",
    "setup_train(run, model_selected)\n",
    "model = Train(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724f65afd8ddeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train VAE with a preprocessed MSA\n",
    ":param conf_path: path to the configuration file of the project\n",
    ":return:\n",
    "\"\"\"\n",
    "# logging\n",
    "train_log = open(os.path.join(run.logs, 'train_log.txt'), \"w\")\n",
    "model = Train(run)\n",
    "with Capturing() as output_train:\n",
    "    model.train()\n",
    "train_log.write(\" Training \\n\" + \"\\n\".join(output_train) + f'\\n{\"=\" * 80}\\n')\n",
    "train_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81926bf7b9c11c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Do I work with conditional model? \"\"\"\n",
    "\n",
    "load_from_pkl(os.path.join(run.model, \"model_params.pkl\"))['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42662ecb12708231",
   "metadata": {},
   "source": [
    "### Generative Capacity evaluation\n",
    "If you wish to obtain estimates of your model's generative capacity, please set run_capacity_test to true in the configuration file before starting the training.\n",
    "\n",
    "This test generates first and second order statistics of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0880b617c49958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks\n",
    "from notebooks.minimal_version.benchmark import Benchmarker\n",
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks/notebooks/\n",
    "run.weights = f'{run.results[:-7]}model/vae_fold_0_e3999.model'\n",
    "\"\"\" \n",
    "Benchmark model \n",
    "How well our model can regenarate sequences in various sets (positive, negative and training)\n",
    "\"\"\"\n",
    "N_SAMPLES = 500\n",
    "\n",
    "Benchmarker(run, samples=N_SAMPLES).bench_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d6d94fb6b300f",
   "metadata": {},
   "source": [
    "### Projection to the latent space\n",
    "Project all points to the latent space and make custom selection of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2dbc32c8ec2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks\n",
    "from matplotlib import pyplot as plt\n",
    "from notebooks.minimal_version.latent_space import LatentSpace\n",
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks/notebooks/\n",
    "for epoch in range(1,15000):\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        # Projection to the latent space\n",
    "        # Show your queries\n",
    "        run.weights = f'{run.results[:-7]}model/vae_fold_0_e{epoch}.model'\n",
    "        latent_space = LatentSpace(run)\n",
    "        msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "\n",
    "\n",
    "        query_coords = latent_space.key_to_embedding(run.fixed_sequences)\n",
    "\n",
    "        custom_sequences = []  # give keys to MSA and embed them to the latent space\n",
    "\n",
    "\n",
    "        fig_lat, ax = plt.subplots(1, 1)\n",
    "\n",
    "        ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "        ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "\n",
    "        # Project \n",
    "        for seq_id, seq_mu in enumerate(custom_sequences):\n",
    "            ax.plot(seq_mu[0], seq_mu[1], '.', color='black', alpha=1, markersize=5,\n",
    "                    label='({})'.format(seq_id))\n",
    "            \n",
    "            ax.annotate(str(seq_id), (seq_mu[0], seq_mu[1]))\n",
    "        ax.set_xlabel(\"$Z_1$\")\n",
    "        ax.set_ylabel(\"$Z_2$\")\n",
    "        ax.set_title(f\"Latent space projection epoch {epoch}\")\n",
    "        fig_lat.savefig(os.path.join(run.results, f\"latent_space_e{epoch}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks\n",
    "from matplotlib import pyplot as plt\n",
    "from notebooks.minimal_version.latent_space import LatentSpace\n",
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks/notebooks/\n",
    "\n",
    "# Projection to the latent space\n",
    "# Show your queries\n",
    "run.weights = f'{run.result}/model/vae_fold_0.model'\n",
    "latent_space = LatentSpace(run)\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "\n",
    "\n",
    "query_coords = latent_space.key_to_embedding(run.fixed_sequences)\n",
    "\n",
    "custom_sequences = []  # give keys to MSA and embed them to the latent space\n",
    "\n",
    "conditional = True\n",
    "fig_lat, ax = plt.subplots(1, 1)\n",
    "if conditional:\n",
    "    for i,label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 0:\n",
    "        #if label[0] == 1:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='red')\n",
    "        else:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='blue')\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='k')\n",
    "else:\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "\n",
    "# Project \n",
    "for seq_id, seq_mu in enumerate(custom_sequences):\n",
    "    ax.plot(seq_mu[0], seq_mu[1], '.', color='black', alpha=1, markersize=5,\n",
    "            label='({})'.format(seq_id))\n",
    "    \n",
    "    ax.annotate(str(seq_id), (seq_mu[0], seq_mu[1]))\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "ax.set_title(f\"Latent space projection final\")\n",
    "if conditional:\n",
    "    fig_lat.savefig(os.path.join(run.results, f\"latent_space_conditional.png\"))\n",
    "else:\n",
    "    fig_lat.savefig(os.path.join(run.results, f\"latent_space.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb0af1",
   "metadata": {},
   "source": [
    "### 3D Projection to the latent space\n",
    "Project all points to the latent space and make custom selection of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks\n",
    "from matplotlib import pyplot as plt\n",
    "from notebooks.minimal_version.latent_space import LatentSpace\n",
    "%cd /Users/dahala/GitHub/VAE-enzymes/vae_notebooks/notebooks/\n",
    "\n",
    "# Projection to the latent space\n",
    "# Show your queries\n",
    "#run.weights = f'{run.result}/model/vae_fold_0_e9999.model'\n",
    "latent_space = LatentSpace(run)\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "\n",
    "\n",
    "query_coords = latent_space.key_to_embedding(run.fixed_sequences)\n",
    "\n",
    "\n",
    "conditional = True\n",
    "# Prepare arrays to store points for each label\n",
    "red_points = []\n",
    "blue_points = []\n",
    "\n",
    "if conditional:\n",
    "    for i, label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 0:\n",
    "        #if label[0] == 1:\n",
    "            red_points.append(msa_embeddings[i].numpy())\n",
    "        else:\n",
    "            blue_points.append(msa_embeddings[i].numpy())\n",
    "\n",
    "# Convert to NumPy arrays for easier handling\n",
    "red_points = np.array(red_points)\n",
    "blue_points = np.array(blue_points)\n",
    "\n",
    "angles = [(20, 30), (20, 80), (20, 130), (20, 180), (20, 240), (90, 0)]\n",
    "\n",
    "# Create a figure with 4 subplots for different angles\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "\n",
    "for idx, (elev, azim) in enumerate(angles):\n",
    "    ax = fig.add_subplot(2, 3, idx + 1, projection='3d')\n",
    "\n",
    "    # Plot all red points in one scatter call\n",
    "    if red_points.size > 0:\n",
    "        ax.scatter(red_points[:, 0], red_points[:, 1], red_points[:, 2], alpha=1, s=3, color='red')\n",
    "\n",
    "    # Plot all blue points in one scatter call\n",
    "    if blue_points.size > 0:\n",
    "        ax.scatter(blue_points[:, 0], blue_points[:, 1], blue_points[:, 2], alpha=0.1, s=3, color='blue')\n",
    "\n",
    "    # Plot query coordinates\n",
    "    ax.scatter(query_coords[0::3], query_coords[1::3], query_coords[2::3], color='k', s=20)\n",
    "\n",
    "    # Set labels and title for each subplot\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_zlabel(\"$Z_3$\")\n",
    "    ax.set_title(f\"View (elev={elev}, azim={azim})\")\n",
    "    \n",
    "    # Set the view angle\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run.results, f\"latent_space_3d.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be569ab1800fe63e",
   "metadata": {},
   "source": [
    "### Generate ancestors\n",
    "Using straight evolution protocol  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0529b864b09d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.minimal_version.evolution_protocols.straight_evolution import StraightEvolution\n",
    "#run.weights = f'../results/EnzymeMiner_PtUGT1/model/vae_fold_0_e3999.model'\n",
    "latent_space = LatentSpace(run)\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "protocol = StraightEvolution(run)\n",
    "ancestors = protocol.get_ancestors(profile=False)  # FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aa6ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['notebooks.minimal_version.latent_space'])\n",
    "from notebooks.minimal_version.latent_space import LatentSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4310d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fireprot_ancestors = {}\n",
    "for i in range(151,300):\n",
    "    seq = np.loadtxt(f'../../FireProtASR_results/ancestrals/node_{i}.fas',dtype=str)\n",
    "    seq = str(seq)\n",
    "    fireprot_ancestors[f'anc{i}'] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_name = 'PFAM201'#'GASP'#'EnzymeMiner_PtUGT1'\n",
    "fireprot_ancestors_df = encode_custom_seqs('At71B1_ancestral_sequences',hmm_name,run.root_dir,fasta_ext='fasta')#,model= f'vae_fold_0_e6499.model',batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fireprot_ancestors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6515fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ancestors_df = fireprot_ancestors_df.loc[['anc_294','anc_293','anc_292','anc_289','anc_288','anc_209','anc_200','anc_196','anc_151']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ea0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.fixed_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88747c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, color='lightgray')\n",
    "\n",
    "\n",
    "# Project \n",
    "i = 0\n",
    "for seq_id, seq in ancestors.items():\n",
    "    seq = ''.join(seq)\n",
    "    seq_mu = latent_space.encode(seq)[0][0]\n",
    "    if i == 0:\n",
    "        ax.plot(seq_mu[0], seq_mu[1], '.', color='red', alpha=0.2, markersize=5,\n",
    "            label='VAE ancestors')\n",
    "        i += 1\n",
    "    else:\n",
    "        ax.plot(seq_mu[0], seq_mu[1], '.', color='red', alpha=0.2, markersize=5)\n",
    "\n",
    "i = 0\n",
    "for mu1,mu2 in query_ancestors_df[['mu1','mu2']].values:\n",
    "    if i == 0:\n",
    "        ax.plot(mu1, mu2, '.', color='blue', alpha=0.2, markersize=5,\n",
    "            label='FireProt ancestors')\n",
    "        i += 1\n",
    "    else:\n",
    "        ax.plot(mu1, mu2, '.', color='blue', alpha=0.2, markersize=5)\n",
    "\n",
    "ax.scatter(query_coords[0], query_coords[1], color='white',edgecolor='k', s=50, label='Query', zorder=10)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_anc.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c1ea8",
   "metadata": {},
   "source": [
    "### Sequence Projection\n",
    "Projecting custom sequence to latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec81fbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc93864",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space = LatentSpace(run)\n",
    "#hmm_name = 'PFAM201'\n",
    "hmm_name = 'GASP'\n",
    "#hmm_name = 'EnzymeMiner_PtUGT1'\n",
    "known_df_ = encode_custom_seqs('KnownGT1',hmm_name,run.result,fasta_ext='faa',model= f'vae_fold_0.model',batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf7e54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KnownUGT_df = pd.read_excel('../../UGT_names_excel.xlsx',index_col=2)\n",
    "KnownUGT_df = KnownUGT_df.merge(known_df_, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bb8d3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_df = pd.read_csv('../../All_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_unique = All_data_df.drop_duplicates(subset='Accession', keep='first')\n",
    "with open('../datasets/All_data_unique.fasta', 'w') as f:\n",
    "    for index, row in All_data_unique.iterrows():\n",
    "        if not row['Official_name'].count('+') == 1:\n",
    "            f.write(f\">{row['Official_name']}\\n{row['Sequence']}\\n\")\n",
    "all_encode = encode_custom_seqs('All_data_unique',hmm_name,run.result,fasta_ext='fasta',model= f'vae_fold_0.model',batch_size=1)\n",
    "All_data_unique = All_data_unique.merge(all_encode, left_on='Official_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset1 = All_data_df[All_data_df.ID=='Dataset1']\n",
    "with open('../datasets/Dataset1.faa','w') as f:\n",
    "    for enz,seq in zip(Dataset1['Official_name'],Dataset1['Sequence']):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "dataset1_encode = encode_custom_seqs('Dataset1',hmm_name,run.result,fasta_ext='faa',model= f'vae_fold_0.model',batch_size=1)\n",
    "Dataset1 = Dataset1.merge(dataset1_encode, left_on='Official_name', right_index=True)\n",
    "Dataset1_test = Dataset1[Dataset1.Acceptor.isin(['3,4-Dichloroaniline', '3,4-Dichlorothiophenol', 'Resveratrol',\n",
    "                                                  'Cinnamyl alcohol', 'Quercetin', 'Cinnamic acid', 'Linalool',\n",
    "                                                    'Ferulic acid', 'Capsaicin', 'Naringenin'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ac5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DON_GT1_kin = All_data_df[All_data_df.ID=='DON_GT1_kin']\n",
    "DON_GT1_kin_unique = DON_GT1_kin.drop_duplicates(subset='Official_name')\n",
    "with open('../datasets/DON_GT1_kin.faa','w') as f:\n",
    "    for enz,seq in zip(DON_GT1_kin_unique.Official_name,DON_GT1_kin_unique.Sequence):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "don_gt1_kin_df = encode_custom_seqs('DON_GT1_kin',hmm_name,run.result,fasta_ext='faa',model= f'vae_fold_0.model',batch_size=1)\n",
    "DON_GT1_kin_unique = DON_GT1_kin_unique.merge(don_gt1_kin_df, left_on='Official_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cfb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PtUGT1_TMmut = All_data_df[(All_data_df.ID == 'PtUGT1_TMmut')&(All_data_df.Measurement_type=='Tm')]\n",
    "\n",
    "with open('../datasets/PtUGT1_TMmut.faa', 'w') as f:\n",
    "    for enz,mut, seq in zip(PtUGT1_TMmut['Official_name'],PtUGT1_TMmut['Mutation_position'], PtUGT1_TMmut['Sequence']):\n",
    "        f.write(f'>{enz} | {mut}\\n{seq}\\n')\n",
    "\n",
    "PtUGT1_TMmut_encode = encode_custom_seqs('PtUGT1_TMmut',hmm_name,run.result,fasta_ext='faa',model= f'vae_fold_0.model',batch_size=1)\n",
    "for col in PtUGT1_TMmut_encode.columns:\n",
    "    PtUGT1_TMmut[col] = PtUGT1_TMmut_encode[col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CGT_sol = All_data_df[All_data_df.ID=='CGT_sol']\n",
    "with open('../datasets/CGT_sol.faa','w') as f:\n",
    "    for enz,seq in zip(CGT_sol['Official_name'],CGT_sol['Sequence']):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "cgt_sol_df = encode_custom_seqs('CGT_sol',hmm_name,run.result,fasta_ext='faa',model= f'vae_fold_0.model',batch_size=1)\n",
    "CGT_sol = CGT_sol.merge(cgt_sol_df, left_on='Official_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anthranilates_GT1 = All_data_df[(All_data_df.ID == 'Anthranilates_GT1')]\n",
    "with open('../datasets/Anthranilates_GT1.faa', 'w') as f:\n",
    "    for enz, seq in zip(Anthranilates_GT1['Official_name'], Anthranilates_GT1['Sequence']):\n",
    "        if enz != 'Sl_UGT72B68+GmSuSy':\n",
    "            f.write(f'>{enz}\\n{seq}\\n')\n",
    "anthranilates_gt1_encode = encode_custom_seqs('Anthranilates_GT1',hmm_name,run.result,fasta_ext='faa',model= f'vae_fold_0.model',batch_size=1)\n",
    "Anthranilates_GT1 = Anthranilates_GT1.merge(anthranilates_gt1_encode, left_on='Official_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28a34d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "KnownGT_colors = {}\n",
    "okabe_ito_colors_ext = ['white','lightgray','#000000','#750000','#56B4E9','#E69F00','#009E73','#D55E00','#0072B2','#CC79A7','#F0E442','darkgray']\n",
    "colors=okabe_ito_colors_ext[3:]+['darkgreen']+['#FF6865']\n",
    "for i,phylum in enumerate(pd.unique(KnownUGT_df.Phylum)):\n",
    "    KnownGT_colors[phylum] = colors[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad46b5a2",
   "metadata": {},
   "source": [
    "fig_lat, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "\n",
    "\n",
    "Project\n",
    "for mu1,mu2 in query_df[['mu1','mu2']].values:\n",
    "    ax.scatter(mu1, mu2, color='lightblue', alpha=1, s=100, zorder=2,edgecolor='black')\n",
    "\n",
    "#ax.scatter(seq_mu[0], seq_mu[1], color='green', alpha=1, s=100,edgecolor='black', zorder=2)\n",
    "    \n",
    "    #ax.annotate(str(seq_id), (seq_mu[0], seq_mu[1]))\n",
    "ax.scatter(query_coords[0::2], query_coords[1::2], color='gold', alpha=1, s=20,edgecolor='black', zorder=5)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "ax.legend(fontsize=10)\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_custom_seq.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3572f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "ax.scatter(All_data_unique.mu1, All_data_unique.mu2, color='gray', alpha=1, s=30,edgecolor='black', zorder=3)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='blue')\n",
    "#ax.set_xlim(-10,5)\n",
    "#ax.set_ylim(-5,11)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_exp_enz.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in ['3,4-Dichloroaniline', '3,4-Dichlorothiophenol', 'Resveratrol',\n",
    "                                                  'Cinnamyl alcohol', 'Quercetin', 'Cinnamic acid', 'Linalool',\n",
    "                                                    'Ferulic acid', 'Capsaicin', 'Naringenin']:\n",
    "    print(All_data_df[All_data_df.Acceptor==sub].Acceptor.unique(),All_data_df[All_data_df.Acceptor==sub].Acceptor_cid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, axes = plt.subplots(2, 5,figsize=(20,10))\n",
    "Dataset1_test_bin = Dataset1_test[Dataset1_test.Measurement_type=='Activity_score']\n",
    "# Project\n",
    "for ax,substrate in zip(axes.flatten(),['3,4-Dichloroaniline', '3,4-Dichlorothiophenol', 'Resveratrol',\n",
    "                                                  'Cinnamyl alcohol', 'Quercetin', 'Cinnamic acid', 'Linalool',\n",
    "                                                    'Ferulic acid', 'Capsaicin', 'Naringenin']):\n",
    "    subset_ = Dataset1_test_bin[(Dataset1_test_bin.Acceptor==substrate)]\n",
    "    ax.scatter(subset_.mu1, subset_.mu2, c=subset_.Measurement_val.to_numpy(dtype=float), alpha=1, s=20,edgecolor='black', zorder=3,cmap='coolwarm')\n",
    "    ax.set_title(substrate)\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_aspect('equal')\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_dataset1.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7712b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(1, 2,figsize=(10,5))\n",
    "\n",
    "# Project\n",
    "ax[0].scatter(DON_GT1_kin_unique.mu1, DON_GT1_kin_unique.mu2, c=DON_GT1_kin[DON_GT1_kin.Measurement_type=='Km'].Measurement_val.to_numpy(dtype=float), alpha=1, s=20,edgecolor='black', zorder=2,label='DON_GT1_Km')\n",
    "ax[1].scatter(DON_GT1_kin_unique.mu1, DON_GT1_kin_unique.mu2, c=DON_GT1_kin[DON_GT1_kin.Measurement_type=='kcat'].Measurement_val.to_numpy(dtype=float), alpha=1, s=20,edgecolor='black', zorder=2,label='DON_GT1_kcat')\n",
    "for i in range(2):\n",
    "    ax[i].plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "    ax[i].set_xlabel(\"$Z_1$\")\n",
    "    ax[i].set_ylabel(\"$Z_2$\")\n",
    "    ax[i].legend(fontsize=10)\n",
    "    ax[i].set_box_aspect(1)\n",
    "    #ax[i].set_ylim(0,5)\n",
    "    #ax[i].set_xlim(-10,0)\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_DON_GT1_kin.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "\n",
    "ax.scatter(PtUGT1_TMmut.mu1, PtUGT1_TMmut.mu2, c=PtUGT1_TMmut.Measurement_val.to_numpy(dtype=float), alpha=1, s=30,edgecolor='black', zorder=3)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "#ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "#ax.set_xlim(-4.3,-4.35)\n",
    "#ax.set_ylim(PtUGT1_TMmut.mu2.min()*0.99,0.34)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_PtUGT1_TMmut.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "\n",
    "ax.scatter(PtUGT1_TMmut.mu1, PtUGT1_TMmut.mu2, c=PtUGT1_TMmut.Mutation_position.str.count(','), alpha=1, s=30,edgecolor='black', zorder=3)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "#ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "#ax.set_xlim(-4.3,-4.35)\n",
    "#ax.set_ylim(PtUGT1_TMmut.mu2.min()*0.99,0.34)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_PtUGT1_TMmut_mutnumb.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08870358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Prepare the data\n",
    "#X = PtUGT1_TMmut[['mu1', 'mu2']]\n",
    "#y = PtUGT1_TMmut['Measurement_val'].astype(float)  # Ensure the target variable is float\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = PtUGT1_TMmut[PtUGT1_TMmut.Mutation_position.str.count(',')<1][['mu1', 'mu2']]\n",
    "y_train = PtUGT1_TMmut[PtUGT1_TMmut.Mutation_position.str.count(',')<1]['Measurement_val'].astype(float)\n",
    "X_test = PtUGT1_TMmut[PtUGT1_TMmut.Mutation_position.str.count(',')>0][['mu1', 'mu2']]\n",
    "y_test = PtUGT1_TMmut[PtUGT1_TMmut.Mutation_position.str.count(',')>0]['Measurement_val'].astype(float)\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "pearson = pearsonr(y_test, y_pred)\n",
    "spearman = spearmanr(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Pearson Correlation: {pearson[0]}\")\n",
    "print(f\"Spearman Correlation: {spearman[0]}\")\n",
    "\n",
    "# Display the coefficients\n",
    "print(f\"Coefficients: {model.coef_}\")\n",
    "print(f\"Intercept: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axis = plt.subplots(1,1,figsize=(6,6))\n",
    "# Plot the data\n",
    "axis.scatter(y_test, y_pred, c=PtUGT1_TMmut.loc[y_test.index].Mutation_position.str.count(','))\n",
    "axis.set_xlabel(\"True Values\")\n",
    "axis.set_ylabel(\"Predictions\")\n",
    "axis.set_box_aspect(1)\n",
    "axis.plot([0, 1], [1, 0], transform=axis.transAxes, ls=\"--\", c=\"grey\")\n",
    "plt.savefig(os.path.join(run.results, \"regression_PtUGT1_TMmut.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(PtUGT1_TMmut.Mutation_position.str.count(','),PtUGT1_TMmut.Measurement_val.to_numpy(dtype=float))\n",
    "plt.xlabel('Number of mutations')\n",
    "plt.ylabel('Measurement value')\n",
    "pearsonr(PtUGT1_TMmut.Mutation_position.str.count(','),PtUGT1_TMmut.Measurement_val.to_numpy(dtype=float))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64735747",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "CGT_sol = CGT_sol.sort_values(by='Measurement_val')\n",
    "ax.scatter(CGT_sol.mu1, CGT_sol.mu2, c=CGT_sol.Measurement_val.to_numpy(dtype=float), alpha=1, s=30,edgecolor='black', zorder=3)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "#ax.set_xlim(-10,5)\n",
    "#ax.set_ylim(-5,11)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_CGT_sol.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, axes = plt.subplots(2, 3,figsize=(15,10))\n",
    "# Project\n",
    "for ax,substrate in zip(axes.flatten(),Anthranilates_GT1.Acceptor.unique()):\n",
    "    subset_ = Anthranilates_GT1[(Anthranilates_GT1.Acceptor==substrate)]\n",
    "    ax.scatter(subset_.mu1, subset_.mu2, c=subset_.Measurement_val.to_numpy(dtype=float), alpha=1, s=20,edgecolor='black', zorder=3)\n",
    "    ax.set_title(substrate)\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_aspect('equal')\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_Anthranilates_GT1.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a15b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, zorder=1,color='darkgray')\n",
    "\n",
    "\n",
    "# Project\n",
    "for phylum in pd.unique(KnownUGT_df.Phylum):\n",
    "    df_ = gaplimiter_df(KnownUGT_df[KnownUGT_df.Phylum == phylum],threshold=0.8)\n",
    "    if df_.shape[0] == 0:\n",
    "        continue\n",
    "    mu1_ = df_.mu1\n",
    "    mu2_ = df_.mu2\n",
    "    ax.scatter(mu1_, mu2_, color=KnownGT_colors[phylum], alpha=1, s=50,edgecolor='black', zorder=2, label = phylum)\n",
    "    #ax.annotate(str(seq_id), (seq_mu[0], seq_mu[1]))\n",
    "#ax.scatter(query_coords[0::2], query_coords[1::2], color='red', alpha=1, s=20,edgecolor='black', zorder=2)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "ax.legend(fontsize=10)\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_knownGT1_seq.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58df31c",
   "metadata": {},
   "source": [
    "### Sequence Projection for C-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_df = pd.read_csv('../../All_data.csv')\n",
    "Dataset1 = All_data_df[All_data_df.ID=='Dataset1']\n",
    "latent_space = LatentSpace(run)\n",
    "hmm_name = 'EnzymeMiner_PtUGT1'#'PFAM201''GASP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4eeff",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset1_Dichloroaniline_bin = Dataset1[(Dataset1.Acceptor=='3,4-Dichloroaniline')&(Dataset1.Measurement_type=='Activity_score')]\n",
    "Dataset1_Dichloroaniline_labels = torch.tensor([[1,0] if float(val) == 1 else [0,1] for val in Dataset1_Dichloroaniline_bin['Measurement_val']])\n",
    "Dataset1_Dichloroaniline_labels_neg = torch.tensor([[1,0] if float(val) == 0 else [0,1] for val in Dataset1_Dichloroaniline_bin['Measurement_val']])\n",
    "with open('../datasets/Dataset1_Dichloroaniline.faa','w') as f:\n",
    "    for enz,seq in zip(Dataset1_Dichloroaniline_bin['Official_name'],Dataset1_Dichloroaniline_bin['Sequence']):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "dataset1_bin_encode = encode_custom_seqs_conditional('Dataset1_Dichloroaniline',hmm_name,run.result,Dataset1_Dichloroaniline_labels,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_Dichloroaniline_bin = Dataset1_Dichloroaniline_bin.merge(dataset1_bin_encode, left_on='Official_name', right_index=True)\n",
    "dataset1_bin_encode_neg = encode_custom_seqs_conditional('Dataset1_Dichloroaniline',hmm_name,run.result,Dataset1_Dichloroaniline_labels_neg,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_Dichloroaniline_bin = Dataset1_Dichloroaniline_bin.merge(dataset1_bin_encode_neg[['mu1','mu2']], left_on='Official_name', right_index=True,suffixes=('','_neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2bd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset1_DCP_bin = Dataset1[(Dataset1.Acceptor=='3,4-Dichlorothiophenol')&(Dataset1.Measurement_type=='Activity_score')]\n",
    "Dataset1_DCP_labels = torch.tensor([[1,0] if float(val) == 1 else [0,1] for val in Dataset1_DCP_bin['Measurement_val']])\n",
    "Dataset1_DCP_labels_neg = torch.tensor([[1,0] if float(val) == 0 else [0,1] for val in Dataset1_DCP_bin['Measurement_val']])\n",
    "with open('../datasets/Dataset1_DCP.faa','w') as f:\n",
    "    for enz,seq in zip(Dataset1_DCP_bin['Official_name'],Dataset1_DCP_bin['Sequence']):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "dataset1_bin_encode = encode_custom_seqs_conditional('Dataset1_DCP',hmm_name,run.result,Dataset1_DCP_labels,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_DCP_bin = Dataset1_DCP_bin.merge(dataset1_bin_encode, left_on='Official_name', right_index=True)\n",
    "dataset1_bin_encode_neg = encode_custom_seqs_conditional('Dataset1_DCP',hmm_name,run.result,Dataset1_DCP_labels_neg,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_DCP_bin = Dataset1_DCP_bin.merge(dataset1_bin_encode_neg[['mu1','mu2']], left_on='Official_name', right_index=True,suffixes=('','_neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "ax.scatter(Dataset1_Dichloroaniline_bin.mu1, Dataset1_Dichloroaniline_bin.mu2, c=Dataset1_Dichloroaniline_bin.Measurement_val.to_numpy(dtype=float), alpha=1, s=30,edgecolor='black', zorder=3,cmap='coolwarm')\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "conditional = True\n",
    "if conditional:\n",
    "    for i,label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 1:\n",
    "        #if label[0] == 0:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='red')\n",
    "        else:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='blue')\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='k')\n",
    "else:\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "#ax.set_xlim(-3,3)\n",
    "#ax.set_ylim(-5,2)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_D1_Dichloroaniline_bin.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badcec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "ax.scatter(Dataset1_DCP_bin.mu1, Dataset1_DCP_bin.mu2, c=Dataset1_DCP_bin.Measurement_val.to_numpy(dtype=float), alpha=1, s=30,edgecolor='black', zorder=3,cmap='coolwarm')\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "conditional = True\n",
    "if conditional:\n",
    "    for i,label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 1:\n",
    "        #if label[0] == 0:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='red')\n",
    "        else:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='blue')\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='k')\n",
    "else:\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "#ax.set_xlim(-3,3)\n",
    "#ax.set_ylim(-5,11)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_D1_DCP_bin.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fadb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "Dataset1_Dichloroaniline_bin_subset = Dataset1_Dichloroaniline_bin[Dataset1_Dichloroaniline_bin.Measurement_val.to_numpy(dtype=float)==1]\n",
    "ax.scatter(Dataset1_Dichloroaniline_bin_subset.mu1, Dataset1_Dichloroaniline_bin_subset.mu2, alpha=0.5, s=30,edgecolor='black', zorder=3,cmap='red')\n",
    "ax.scatter(Dataset1_Dichloroaniline_bin_subset.mu1_neg, Dataset1_Dichloroaniline_bin_subset.mu2_neg, alpha=0.5, s=30,edgecolor='black', zorder=3,cmap='blue')\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "conditional = True\n",
    "if conditional:\n",
    "    for i,label in enumerate(msa_key_label_order.values()):\n",
    "        #if label[0] == 0:\n",
    "        if label[0] == 1:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='red')\n",
    "        else:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='blue')\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='k')\n",
    "else:\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "#ax.set_xlim(-3,3)\n",
    "#ax.set_ylim(-5,2)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_D1_Dichloroaniline_bin_pos_reversed.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lat, ax = plt.subplots(figsize=(6,6))\n",
    "# Project\n",
    "Dataset1_DCP_bin_subset = Dataset1_DCP_bin[Dataset1_DCP_bin.Measurement_val.to_numpy(dtype=float)==1]\n",
    "ax.scatter(Dataset1_DCP_bin_subset.mu1, Dataset1_DCP_bin_subset.mu2, alpha=0.5, s=30,edgecolor='black', zorder=3,cmap='red')\n",
    "ax.scatter(Dataset1_DCP_bin_subset.mu1_neg, Dataset1_DCP_bin_subset.mu2_neg, alpha=0.5, s=30,edgecolor='black', zorder=3,cmap='navy')\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "\n",
    "conditional = True\n",
    "if conditional:\n",
    "    for i,label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 1:\n",
    "        #if label[0] == 0:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='red')\n",
    "        else:\n",
    "            ax.plot(msa_embeddings[i, 0], msa_embeddings[i, 1], '.', alpha=0.1, markersize=3, color='blue')\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='k')\n",
    "else:\n",
    "    ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "    ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "#ax.set_xlim(-3,3)\n",
    "#ax.set_ylim(-5,2)\n",
    "ax.set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, \"latent_space_with_D1_DCP_bin_pos_reversed.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a362f",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset1_Dichloroaniline_bin = Dataset1[(Dataset1.Acceptor=='3,4-Dichloroaniline')&(Dataset1.Measurement_type=='Activity_score')]\n",
    "Dataset1_Dichloroaniline_labels = torch.tensor([[1,0] if float(val) == 1 else [0,1] for val in Dataset1_Dichloroaniline_bin['Measurement_val']])\n",
    "Dataset1_Dichloroaniline_labels_neg = torch.tensor([[1,0] if float(val) == 0 else [0,1] for val in Dataset1_Dichloroaniline_bin['Measurement_val']])\n",
    "with open('../datasets/Dataset1_Dichloroaniline.faa','w') as f:\n",
    "    for enz,seq in zip(Dataset1_Dichloroaniline_bin['Official_name'],Dataset1_Dichloroaniline_bin['Sequence']):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "dataset1_bin_encode = encode_custom_seqs_conditional_3D('Dataset1_Dichloroaniline',hmm_name,run.result,Dataset1_Dichloroaniline_labels,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_Dichloroaniline_bin = Dataset1_Dichloroaniline_bin.merge(dataset1_bin_encode, left_on='Official_name', right_index=True)\n",
    "dataset1_bin_encode_neg = encode_custom_seqs_conditional_3D('Dataset1_Dichloroaniline',hmm_name,run.result,Dataset1_Dichloroaniline_labels_neg,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_Dichloroaniline_bin = Dataset1_Dichloroaniline_bin.merge(dataset1_bin_encode_neg[['mu1','mu2','mu3']], left_on='Official_name', right_index=True,suffixes=('','_neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99782e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset1_DCP_bin = Dataset1[(Dataset1.Acceptor=='3,4-Dichlorothiophenol')&(Dataset1.Measurement_type=='Activity_score')]\n",
    "Dataset1_DCP_labels = torch.tensor([[1,0] if float(val) == 1 else [0,1] for val in Dataset1_DCP_bin['Measurement_val']])\n",
    "Dataset1_DCP_labels_neg = torch.tensor([[1,0] if float(val) == 0 else [0,1] for val in Dataset1_DCP_bin['Measurement_val']])\n",
    "with open('../datasets/Dataset1_DCP.faa','w') as f:\n",
    "    for enz,seq in zip(Dataset1_DCP_bin['Official_name'],Dataset1_DCP_bin['Sequence']):\n",
    "        f.write(f'>{enz}\\n{seq}\\n')\n",
    "dataset1_bin_encode = encode_custom_seqs_conditional_3D('Dataset1_DCP',hmm_name,run.result,Dataset1_DCP_labels,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_DCP_bin = Dataset1_DCP_bin.merge(dataset1_bin_encode, left_on='Official_name', right_index=True)\n",
    "dataset1_bin_encode_neg = encode_custom_seqs_conditional_3D('Dataset1_DCP',hmm_name,run.result,Dataset1_DCP_labels_neg,fasta_ext='faa',model= f'vae_fold_0.model')\n",
    "Dataset1_DCP_bin = Dataset1_DCP_bin.merge(dataset1_bin_encode_neg[['mu1','mu2','mu3']], left_on='Official_name', right_index=True,suffixes=('','_neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection to the latent space\n",
    "# Show your queries\n",
    "#run.weights = f'{run.result}/model/vae_fold_0_e9999.model'\n",
    "latent_space = LatentSpace(run)\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "\n",
    "\n",
    "query_coords = latent_space.key_to_embedding(run.fixed_sequences)\n",
    "\n",
    "\n",
    "conditional = True\n",
    "# Prepare arrays to store points for each label\n",
    "red_points = []\n",
    "blue_points = []\n",
    "\n",
    "if conditional:\n",
    "    for i, label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 0:\n",
    "        #if label[0] == 1:\n",
    "            red_points.append(msa_embeddings[i].numpy())\n",
    "        else:\n",
    "            blue_points.append(msa_embeddings[i].numpy())\n",
    "\n",
    "# Convert to NumPy arrays for easier handling\n",
    "red_points = np.array(red_points)\n",
    "blue_points = np.array(blue_points)\n",
    "\n",
    "angles = [(20, 30), (20, 80), (20, 130), (20, 180), (20, 240), (90, 0)]\n",
    "\n",
    "# Create a figure with 4 subplots for different angles\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "\n",
    "for idx, (elev, azim) in enumerate(angles):\n",
    "    ax = fig.add_subplot(2, 3, idx + 1, projection='3d')\n",
    "    \n",
    "    \n",
    "    # Plot all red points in one scatter call\n",
    "    if red_points.size > 0:\n",
    "        ax.scatter(red_points[:, 0], red_points[:, 1], red_points[:, 2], alpha=0.1, s=3, color='red')\n",
    "\n",
    "    # Plot all blue points in one scatter call\n",
    "    if blue_points.size > 0:\n",
    "        ax.scatter(blue_points[:, 0], blue_points[:, 1], blue_points[:, 2], alpha=0.1, s=3, color='blue')\n",
    "\n",
    "    # Set labels and title for each subplot\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_zlabel(\"$Z_3$\")\n",
    "    ax.set_title(f\"View (elev={elev}, azim={azim})\")\n",
    "\n",
    "    # Plot Validation Data\n",
    "    ax.scatter(Dataset1_Dichloroaniline_bin.mu1, Dataset1_Dichloroaniline_bin.mu2, Dataset1_Dichloroaniline_bin.mu3, c=Dataset1_Dichloroaniline_bin.Measurement_val.to_numpy(dtype=float), alpha=1, s=30,edgecolor='black', zorder=3,cmap='coolwarm')\n",
    "\n",
    "    # Set the view angle\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run.results, f\"latent_space_3d_wDCA.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863db07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection to the latent space\n",
    "# Show your queries\n",
    "#run.weights = f'{run.result}/model/vae_fold_0_e9999.model'\n",
    "latent_space = LatentSpace(run)\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "\n",
    "\n",
    "query_coords = latent_space.key_to_embedding(run.fixed_sequences)\n",
    "\n",
    "\n",
    "conditional = True\n",
    "# Prepare arrays to store points for each label\n",
    "red_points = []\n",
    "blue_points = []\n",
    "\n",
    "if conditional:\n",
    "    for i, label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 0:\n",
    "        #if label[0] == 1:\n",
    "            red_points.append(msa_embeddings[i].numpy())\n",
    "        else:\n",
    "            blue_points.append(msa_embeddings[i].numpy())\n",
    "\n",
    "# Convert to NumPy arrays for easier handling\n",
    "red_points = np.array(red_points)\n",
    "blue_points = np.array(blue_points)\n",
    "\n",
    "angles = [(20, 30), (20, 80), (20, 130), (20, 180), (20, 240), (90, 0)]\n",
    "Dataset1_Dichloroaniline_bin_subset = Dataset1_Dichloroaniline_bin[Dataset1_Dichloroaniline_bin.Measurement_val.to_numpy(dtype=float)==1]\n",
    "# Create a figure with 4 subplots for different angles\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "\n",
    "for idx, (elev, azim) in enumerate(angles):\n",
    "    ax = fig.add_subplot(2, 3, idx + 1, projection='3d')\n",
    "    \n",
    "    \n",
    "    # Plot all red points in one scatter call\n",
    "    if red_points.size > 0:\n",
    "        ax.scatter(red_points[:, 0], red_points[:, 1], red_points[:, 2], alpha=0.1, s=3, color='red')\n",
    "\n",
    "    # Plot all blue points in one scatter call\n",
    "    if blue_points.size > 0:\n",
    "        ax.scatter(blue_points[:, 0], blue_points[:, 1], blue_points[:, 2], alpha=0.1, s=3, color='blue')\n",
    "\n",
    "    # Set labels and title for each subplot\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_zlabel(\"$Z_3$\")\n",
    "    ax.set_title(f\"View (elev={elev}, azim={azim})\")\n",
    "    \n",
    "    # Plot Validation Data\n",
    "    ax.scatter(Dataset1_Dichloroaniline_bin_subset.mu1, Dataset1_Dichloroaniline_bin_subset.mu2, Dataset1_Dichloroaniline_bin_subset.mu3, alpha=0.8, s=30,edgecolor='black', zorder=1,color='red')\n",
    "    ax.scatter(Dataset1_Dichloroaniline_bin_subset.mu1_neg, Dataset1_Dichloroaniline_bin_subset.mu2_neg, Dataset1_Dichloroaniline_bin_subset.mu3_neg, alpha=0.8, s=30,edgecolor='black', zorder=4,color='blue')\n",
    "\n",
    "    # Set the view angle\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run.results, f\"latent_space_3d_wDCA_pos_reversed.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca54a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection to the latent space\n",
    "# Show your queries\n",
    "#run.weights = f'{run.result}/model/vae_fold_0_e9999.model'\n",
    "latent_space = LatentSpace(run)\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "\n",
    "\n",
    "query_coords = latent_space.key_to_embedding(run.fixed_sequences)\n",
    "\n",
    "\n",
    "conditional = True\n",
    "# Prepare arrays to store points for each label\n",
    "red_points = []\n",
    "blue_points = []\n",
    "\n",
    "if conditional:\n",
    "    for i, label in enumerate(msa_key_label_order.values()):\n",
    "        if label[0] == 0:\n",
    "        #if label[0] == 1:\n",
    "            red_points.append(msa_embeddings[i].numpy())\n",
    "        else:\n",
    "            blue_points.append(msa_embeddings[i].numpy())\n",
    "\n",
    "# Convert to NumPy arrays for easier handling\n",
    "red_points = np.array(red_points)\n",
    "blue_points = np.array(blue_points)\n",
    "\n",
    "angles = [(20, 30), (20, 80), (20, 130), (20, 180), (20, 240), (90, 0)]\n",
    "Dataset1_Dichloroaniline_bin_subset = Dataset1_Dichloroaniline_bin[Dataset1_Dichloroaniline_bin.Measurement_val.to_numpy(dtype=float)==0]\n",
    "# Create a figure with 4 subplots for different angles\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "\n",
    "for idx, (elev, azim) in enumerate(angles):\n",
    "    ax = fig.add_subplot(2, 3, idx + 1, projection='3d')\n",
    "    \n",
    "    \n",
    "    # Plot all red points in one scatter call\n",
    "    if red_points.size > 0:\n",
    "        ax.scatter(red_points[:, 0], red_points[:, 1], red_points[:, 2], alpha=0.1, s=3, color='red')\n",
    "\n",
    "    # Plot all blue points in one scatter call\n",
    "    if blue_points.size > 0:\n",
    "        ax.scatter(blue_points[:, 0], blue_points[:, 1], blue_points[:, 2], alpha=0.1, s=3, color='blue')\n",
    "\n",
    "    # Set labels and title for each subplot\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_zlabel(\"$Z_3$\")\n",
    "    ax.set_title(f\"View (elev={elev}, azim={azim})\")\n",
    "    \n",
    "    # Plot Validation Data\n",
    "    ax.scatter(Dataset1_Dichloroaniline_bin_subset.mu1, Dataset1_Dichloroaniline_bin_subset.mu2, Dataset1_Dichloroaniline_bin_subset.mu3, alpha=0.8, s=30,edgecolor='black', zorder=1,color='blue')\n",
    "    ax.scatter(Dataset1_Dichloroaniline_bin_subset.mu1_neg, Dataset1_Dichloroaniline_bin_subset.mu2_neg, Dataset1_Dichloroaniline_bin_subset.mu3_neg, alpha=0.8, s=30,edgecolor='black', zorder=4,color='red')\n",
    "\n",
    "    # Set the view angle\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(run.results, f\"latent_space_3d_wDCA_neg_reversed.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b73a6db",
   "metadata": {},
   "source": [
    "### Taxonomy Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7e24f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9deb8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "PFAM_UniProt_GT_filter = pd.read_csv('../../random_data/PFAM_UniProt_GT_filter.csv',index_col=0)\n",
    "msa_taxonomy = []\n",
    "for protein in SeqIO.parse(f'{run.result}/msa/training_msa.fasta', \"fasta\"):\n",
    "    protein_name = protein.id\n",
    "    prot_id = protein_name.split('|')[0]\n",
    "    if prot_id in PFAM_UniProt_GT_filter.index:\n",
    "        msa_taxonomy.append([protein_name,PFAM_UniProt_GT_filter.loc[prot_id].superkingdom,PFAM_UniProt_GT_filter.loc[prot_id].kingdom,PFAM_UniProt_GT_filter.loc[prot_id].phylum,PFAM_UniProt_GT_filter.loc[prot_id]['class'],PFAM_UniProt_GT_filter.loc[prot_id].order,PFAM_UniProt_GT_filter.loc[prot_id].family,PFAM_UniProt_GT_filter.loc[prot_id].genus,PFAM_UniProt_GT_filter.loc[prot_id]['EC number'],PFAM_UniProt_GT_filter.loc[prot_id]['Gene Ontology (GO)']])\n",
    "msa_taxonomy = pd.DataFrame(msa_taxonomy,columns=['UniProt','superkingdom','kingdom','phylum','class','order','family','genus','EC','GO'])\n",
    "msa_taxonomy = msa_taxonomy.set_index('UniProt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data_df.groupby('Acceptor').count().T['3,4-Dichlorothiophenol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "colors_kingdom = ['lightcoral','lightblue','gold','forestgreen']\n",
    "fig_lat, ax = plt.subplots(1, 1)\n",
    "ax.scatter(All_data_unique.mu1, All_data_unique.mu2, color='gray', alpha=1, s=30,edgecolor='black', zorder=3)\n",
    "custom_sequences = []  # give keys to MSA and embed them to the latent space\n",
    "for i,kingdom in enumerate(pd.unique(msa_taxonomy.kingdom)):\n",
    "    msa_filter = msa_taxonomy[msa_taxonomy.kingdom == kingdom]\n",
    "    msa_filter_coords = latent_space.key_to_embedding(msa_filter.index)\n",
    "    ax.scatter(msa_filter_coords[0::2], msa_filter_coords[1::2], color=colors_kingdom[i], alpha=0.5, s=5, zorder=2, label = kingdom)\n",
    "\n",
    "#ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "#ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "ax.legend(fontsize=10)\n",
    "ax.set_xlabel(\"$Z_1$\")\n",
    "ax.set_ylabel(\"$Z_2$\")\n",
    "ax.set_title(f\"Latent space projection, Kingdoms, Experimental Enzymes\")\n",
    "fig_lat.savefig(os.path.join(run.results, f\"latent_space_kingdom_exp_enz.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf715114",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,15000):\n",
    "    if (epoch + 1) % 5000 == 0:\n",
    "        run.weights = f'{run.result}model/vae_fold_0_e{epoch}.model'\n",
    "        latent_space = LatentSpace(run)\n",
    "        msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "        colors_kingdom = ['lightcoral','lightblue','gold','forestgreen']\n",
    "        fig_lat, ax = plt.subplots(1, 1)\n",
    "        custom_sequences = []  # give keys to MSA and embed them to the latent space\n",
    "        for i,kingdom in enumerate(pd.unique(msa_taxonomy.kingdom)):\n",
    "            msa_filter = msa_taxonomy[msa_taxonomy.kingdom == kingdom]\n",
    "            msa_filter_coords = latent_space.key_to_embedding(msa_filter.index)\n",
    "            ax.scatter(msa_filter_coords[0::2], msa_filter_coords[1::2], color=colors_kingdom[i], alpha=0.5, s=5, zorder=2, label = kingdom)\n",
    "\n",
    "        #ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "        #ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.set_xlabel(\"$Z_1$\")\n",
    "        ax.set_ylabel(\"$Z_2$\")\n",
    "        ax.set_title(f\"Latent space projection epoch {epoch}, Kingdom\")\n",
    "        fig_lat.savefig(os.path.join(run.results, f\"latent_space_e{epoch}_kingdom.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.weights = f'{run.results[:-7]}model/vae_fold_0_e2999.model'\n",
    "latent_space = LatentSpace(run)\n",
    "#msa_embeddings = latent_space.msa_embeddings[\"mus\"]\n",
    "colors_kingdom = ['lightcoral','lightblue','gold','forestgreen','lightgreen','darkorange','purple','pink','brown','gray','black','red','blue','green','orange','violet','cyan','magenta','yellow','darkred','darkblue','darkgreen','darkorange','darkviolet','darkcyan','darkmagenta','maroon','navy','olive','teal','fuchsia','silver','lime','aqua','white','lightgray','gray','black']\n",
    "#fig_lat, ax = plt.subplots(1, 1)\n",
    "fig_lat, axes = plt.subplots(2, 2, figsize=(12, 12),sharex=True,sharey=True)\n",
    "custom_sequences = []  # give keys to MSA and embed them to the latent space\n",
    "for i,kingdom in enumerate(pd.unique(msa_taxonomy.kingdom)):\n",
    "    ax = axes[i//2,i%2]\n",
    "    msa_kingdoms = msa_taxonomy[msa_taxonomy.kingdom == kingdom]\n",
    "    for i,phylum in enumerate(pd.unique(msa_kingdoms['phylum'])):\n",
    "        msa_filter = msa_kingdoms[msa_kingdoms['phylum'] == phylum]\n",
    "        msa_filter_coords = latent_space.key_to_embedding(msa_filter.index)\n",
    "        ax.scatter(msa_filter_coords[0::2], msa_filter_coords[1::2], color=colors_kingdom[i], alpha=0.5, s=5, zorder=2, label = phylum)\n",
    "\n",
    "#ax.plot(msa_embeddings[:, 0], msa_embeddings[:, 1], '.', alpha=0.1, markersize=3, )\n",
    "#ax.plot(query_coords[0::2], query_coords[1::2], '.', color='red')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.set_xlabel(\"$Z_1$\")\n",
    "    ax.set_ylabel(\"$Z_2$\")\n",
    "    ax.set_title(f'{kingdom}')\n",
    "fig_lat.suptitle(f\"Latent space projection final, phylum\",x=0.5, y=1.02)\n",
    "plt.tight_layout()\n",
    "fig_lat.savefig(os.path.join(run.results, f\"latent_space_kingdom_phylum.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6dddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_filter_coords = latent_space.key_to_embedding(msa_metazoa.index)\n",
    "coords_z1 = msa_filter_coords[0::2]\n",
    "coords_z2 = msa_filter_coords[1::2]\n",
    "mask_ = ((coords_z1<4) & (coords_z2>5))\n",
    "for id in msa_metazoa.iloc[mask_,:].index.str.split('|').str[0]:\n",
    "    print(id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600bb8a1",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ca60c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = latent_space.vae\n",
    "z = torch.tensor(Dataset1_DCP_bin[['mu1','mu2']].to_numpy())\n",
    "c = Dataset1_DCP_labels\n",
    "\n",
    "#if c is not None:\n",
    "#    c = c.repeat(z.shape[0], 1)  # Repeat `c` for each row in `z`, but `c` already matches the batch size here\n",
    "\n",
    "seq_decoding = {}\n",
    "for j in range(10):\n",
    "    with torch.no_grad():\n",
    "        number_sequences = vae.z_to_number_sequences(z[0:2], c[0:2]).cpu().numpy()\n",
    "        test_dict_num = {f\"test{i}\": seq for i, seq in enumerate(number_sequences)}\n",
    "        test_to_store = MSA.number_to_amino(test_dict_num)\n",
    "        seq_decoding[j] = test_to_store['test0']\n",
    "seq_decoding_neg = {}\n",
    "c = Dataset1_DCP_labels_neg\n",
    "for j in range(10):\n",
    "    with torch.no_grad():\n",
    "        number_sequences = vae.z_to_number_sequences(z[0:2], c[0:2]).cpu().numpy()\n",
    "        test_dict_num = {f\"test{i}\": seq for i, seq in enumerate(number_sequences)}\n",
    "        test_to_store = MSA.number_to_amino(test_dict_num)\n",
    "        seq_decoding_neg[j] = test_to_store['test0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    print(''.join(seq_decoding[i]))\n",
    "    print(''.join(seq_decoding_neg[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
